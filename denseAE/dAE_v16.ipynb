{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like 15 but without pt eta phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:53.147535Z",
     "start_time": "2019-07-17T15:37:53.144908Z"
    }
   },
   "outputs": [],
   "source": [
    "AEversion = '16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:53.543859Z",
     "start_time": "2019-07-17T15:37:53.149311Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys, pickle\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:53.751942Z",
     "start_time": "2019-07-17T15:37:53.545776Z"
    },
    "code_folding": [
     1,
     3
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mimperium-sm.hep.caltech.edu\u001b[m  Wed Jul 17 08:37:53 2019\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 21'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  466\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m455M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[1m\u001b[31m 70'C\u001b[m, \u001b[1m\u001b[32m 95 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1782\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30m3041\u001b[m(\u001b[33m1771M\u001b[m)\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 44'C\u001b[m, \u001b[32m  6 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2426\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m2415M\u001b[m)\n"
     ]
    }
   ],
   "source": [
    "import gpustat\n",
    "try:\n",
    "    gpustat.print_gpustat()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:54.106010Z",
     "start_time": "2019-07-17T15:37:53.753744Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:54.112940Z",
     "start_time": "2019-07-17T15:37:54.107685Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../lib')\n",
    "from progressBar import ProgressBar\n",
    "from utils import EarlyStopping, createROC_curve, ELU_ProbNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:54.116603Z",
     "start_time": "2019-07-17T15:37:54.114516Z"
    }
   },
   "outputs": [],
   "source": [
    "dnd = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:54.129879Z",
     "start_time": "2019-07-17T15:37:54.118813Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataLoaders import ParticleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:37:54.133947Z",
     "start_time": "2019-07-17T15:37:54.131621Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ParticleDataset(template='../data/20190717_50part_PtOrder_v3/{}.npy', N_part=30, N_features=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:47.499000Z",
     "start_time": "2019-07-17T15:37:54.135562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Wlnu\n",
      "Fetching qcd\n",
      "Fetching Zll\n",
      "Fetching ttbar\n",
      "Expected 1.00M train\n",
      "Expected 1.00M val\n",
      "\n",
      "Loading Wlnu\n",
      "Loading qcd\n",
      "Loading Zll\n",
      "Loading ttbar\n",
      "+--------+----------+-------+------+\n",
      "| Sample | Evts tot | Train | Val  |\n",
      "+--------+----------+-------+------+\n",
      "|  Wlnu  |  5618k   |  592k | 592k |\n",
      "|  qcd   |  1166k   |  338k | 338k |\n",
      "|  Zll   |  1777k   |  67k  | 67k  |\n",
      "| ttbar  |  6542k   |   3k  |  3k  |\n",
      "+--------+----------+-------+------+\n",
      "Tot training 1.00 M\n",
      "Tot val 1.00 M\n"
     ]
    }
   ],
   "source": [
    "dataset.loadTrainSM(N_train_max=1e6)\n",
    "dataset.charge(dataset.SMMix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:54.078706Z",
     "start_time": "2019-07-17T15:39:47.500594Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ato4l (47.7k)\n",
      "Loading leptoquark (273.6k)\n",
      "Loading hToTauTau (685.8k)\n",
      "Loading hChToTauNu (339.0k)\n"
     ]
    }
   ],
   "source": [
    "dataset.loadValidationSamples('BSM', N_max=1000000000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:54.096386Z",
     "start_time": "2019-07-17T15:39:54.080312Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class AEDenseNet(nn.Module):\n",
    "    def __init__(self, N_part, N_features, dim_hidden, dim_latent, verbose = False):\n",
    "        super(AEDenseNet, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.No = N_part\n",
    "        self.p = N_features-3\n",
    "        self.Nk = dim_latent\n",
    "        \n",
    "        self.encoder_modules = nn.ModuleDict({\n",
    "            'PhiE': self.build_dense(dim_in=self.p*self.No,\n",
    "                                   dim_out=self.Nk,\n",
    "                                   dim_hidden=dim_hidden)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        self.decoder_modules = nn.ModuleDict({\n",
    "            'PhiD': self.build_dense(dim_in=self.Nk,\n",
    "                                   dim_out=(self.p)*self.No,\n",
    "                                   dim_hidden=dim_hidden)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        self.onGPU = False\n",
    "          \n",
    "    def build_dense(self, dim_in, dim_out, dim_hidden=0):\n",
    "        if dim_hidden:\n",
    "            net = nn.Sequential(\n",
    "                                nn.Linear(dim_in, dim_hidden),\n",
    "                                nn.BatchNorm1d(dim_hidden, affine=False),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(dim_hidden, dim_hidden),\n",
    "                                nn.BatchNorm1d(dim_hidden, affine=False),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(dim_hidden, dim_out),\n",
    "                                nn.BatchNorm1d(dim_out, affine=False),\n",
    "                              )\n",
    "        else:\n",
    "            d_avg = int(0.5*(dim_in + dim_out))\n",
    "            net = nn.Sequential(\n",
    "                                nn.Linear(dim_in, d_avg),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(d_avg, dim_out),\n",
    "                              )\n",
    "        return net\n",
    "        \n",
    "    def encode(self, x):\n",
    "        z_raw = self.encoder_modules['PhiE'](x[:,:,3:].contiguous().view(-1, self.p*self.No))\n",
    "        z = F.relu(z_raw)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x_raw = self.decoder_modules['PhiD'](z).view(-1, self.No, self.p)\n",
    "        \n",
    "        # --- Formatting x ----\n",
    "        # eta\n",
    "#         eta = F.hardtanh(x_raw[:,:,0], min_val=-5, max_val=5).view(-1, self.No, 1)\n",
    "        # phi\n",
    "#         phi = torch.fmod(torch.abs(x_raw[:,:,1]), 6.2831853072).view(-1, self.No, 1) - 3.14159265359\n",
    "        \n",
    "        # charge & pId category\n",
    "#         print('Min:', torch.min(x_raw).cpu().detach().numpy())\n",
    "#         print('Max:', torch.max(x_raw).cpu().detach().numpy())\n",
    "#         print('Mean:', torch.mean(x_raw).cpu().detach().numpy())\n",
    "#         cpId_cat = ELU_ProbNorm(x_raw)\n",
    "        cpId_cat = F.softmax(x_raw, dim=-1)\n",
    "        \n",
    "#         x = torch.cat((eta, phi, cpId_cat), 2)\n",
    "        return cpId_cat\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        x_prime = self.decode(z)\n",
    "        return x_prime\n",
    "    \n",
    "    def initWeights(self):\n",
    "        def weights_init(M):\n",
    "            if hasattr(M, 'weight'):\n",
    "                nn.init.xavier_normal_(M.weight.data)\n",
    "        \n",
    "        self.apply(weights_init)\n",
    "    \n",
    "    def useGPU(self, N_GPU=1):\n",
    "        if torch.cuda.is_available():\n",
    "            print('Current device: {} ({} available)'.format(torch.cuda.current_device(), \n",
    "                                                             torch.cuda.device_count()))\n",
    "            os.environ['CUDA_VISIBLE_DEVICES'] = str(N_GPU)\n",
    "            self.N_GPU = N_GPU\n",
    "            torch.cuda.empty_cache()\n",
    "            self.cuda(N_GPU)\n",
    "            gpustat.print_gpustat()\n",
    "            \n",
    "            self.onGPU = True\n",
    "        else: \n",
    "            print('GPU not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:54.107013Z",
     "start_time": "2019-07-17T15:39:54.098049Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEDenseNet(\n",
      "  (encoder_modules): ModuleDict(\n",
      "    (PhiE): Sequential(\n",
      "      (0): Linear(in_features=240, out_features=150, bias=True)\n",
      "      (1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=150, out_features=150, bias=True)\n",
      "      (4): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=150, out_features=80, bias=True)\n",
      "      (7): BatchNorm1d(80, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder_modules): ModuleDict(\n",
      "    (PhiD): Sequential(\n",
      "      (0): Linear(in_features=80, out_features=150, bias=True)\n",
      "      (1): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "      (3): Linear(in_features=150, out_features=150, bias=True)\n",
      "      (4): BatchNorm1d(150, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (5): ReLU()\n",
      "      (6): Linear(in_features=150, out_features=240, bias=True)\n",
      "      (7): BatchNorm1d(240, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Trainable parameters: 141920\n"
     ]
    }
   ],
   "source": [
    "Latent_dimension = 80\n",
    "Hidden_dimension = 150\n",
    "\n",
    "model = AEDenseNet(\n",
    "                   N_part=dataset.inputs.shape[1],\n",
    "                   N_features=dataset.inputs.shape[2],\n",
    "                   dim_hidden=Hidden_dimension,\n",
    "                   dim_latent=Latent_dimension\n",
    "                  )\n",
    "\n",
    "print(model)\n",
    "trainablePars = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('\\nTrainable parameters:', trainablePars)\n",
    "\n",
    "# model.initWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:58.195417Z",
     "start_time": "2019-07-17T15:39:54.108579Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: 0 (8 available)\n",
      "\u001b[1m\u001b[37mimperium-sm.hep.caltech.edu\u001b[m  Wed Jul 17 08:39:58 2019\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 21'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  466\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m455M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[1m\u001b[31m 70'C\u001b[m, \u001b[1m\u001b[32m 95 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 1782\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30m3041\u001b[m(\u001b[33m1771M\u001b[m)\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 45'C\u001b[m, \u001b[32m 22 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 2883\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m2415M\u001b[m) \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m457M\u001b[m)\n"
     ]
    }
   ],
   "source": [
    "model.useGPU(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:58.204074Z",
     "start_time": "2019-07-17T15:39:58.197617Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def criterion(x_in, x_out, reduction='mean'):\n",
    "#     Gaussian\n",
    "#     NLL_gauss = torch.abs(x_in[:,:,:2] - x_out[:,:,:2])\n",
    "    \n",
    "    #Cat cross entropy charge-pId\n",
    "    log_p = torch.log(x_out[:,:,:]).view(-1, 8)\n",
    "    true_cat = torch.argmax(x_in[:,:,3:], dim=2)\n",
    "    NLL_cat = F.nll_loss(log_p, true_cat.view(-1).long(), reduction='none').view(-1, x_in.shape[1], 1)\n",
    "    \n",
    "#     NLL_tot = torch.cat((NLL_gauss, 10*NLL_cat), 2)\n",
    "    NLL_tot = NLL_cat\n",
    "    NLL_perEvent = torch.mean(NLL_tot, dim=1)\n",
    "    \n",
    "    if reduction == 'mean':\n",
    "        NLL_mean = torch.mean(NLL_perEvent, dim=0)\n",
    "        return torch.sum(NLL_mean), NLL_mean.cpu().detach().numpy()\n",
    "    elif reduction == 'none':\n",
    "        return torch.sum(NLL_perEvent, dim=1)\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:58.209490Z",
     "start_time": "2019-07-17T15:39:58.205753Z"
    },
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "training_params = {'batch_size': 128,\n",
    "                   'shuffle': True,\n",
    "                   'num_workers': 1\n",
    "                  }\n",
    "\n",
    "max_epochs = 100\n",
    "\n",
    "eval_params = {'batch_size': 50000,\n",
    "               'num_workers': 3\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:58.213706Z",
     "start_time": "2019-07-17T15:39:58.211191Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T15:39:58.219448Z",
     "start_time": "2019-07-17T15:39:58.215399Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, \n",
    "                              mode='min',\n",
    "                              factor=0.3,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              threshold=1e-4,\n",
    "                              cooldown=2,\n",
    "                              min_lr=1e-7\n",
    "                             )\n",
    "\n",
    "# Early stopping\n",
    "earlyStopping = EarlyStopping(patient=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.218Z"
    },
    "code_folding": [
     92,
     96,
     143
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [####################]  100% - Tot. time: 192.4 s                      \n",
      "Loss: 8.50e-01 - Delta: -8.17e-03\n",
      "Val Loss: 8.35e-01\n",
      "\n",
      "Epoch 2: [####################]  100% - Tot. time: 192.4 s                      \n",
      "Loss: 8.59e-01 - Delta: 9.15e-03 - Trend: 1.73e-02\n",
      "Val Loss: 8.31e-01\n",
      "\n",
      "Epoch 3: [####################]  100% - Tot. time: 192.1 s                      \n",
      "Loss: 8.36e-01 - Delta: -2.26e-02 - Trend: -3.18e-02\n",
      "Val Loss: 8.28e-01\n",
      "\n",
      "Epoch 4: [####################]  100% - Tot. time: 192.3 s                      \n",
      "Loss: 8.49e-01 - Delta: 1.30e-02 - Trend: 3.57e-02\n",
      "Val Loss: 8.35e-01\n",
      "\n",
      "Epoch 5: [####################]  100% - Tot. time: 187.1 s                      \n",
      "Loss: 8.48e-01 - Delta: -1.56e-03 - Trend: -1.46e-02\n",
      "Val Loss: 8.33e-01\n",
      "\n",
      "Epoch 6: [####################]  100% - Tot. time: 184.3 s                      \n",
      "Loss: 8.39e-01 - Delta: -8.59e-03 - Trend: -7.02e-03\n",
      "Val Loss: 8.32e-01\n",
      "\n",
      "Epoch 8: [####################]  100% - Tot. time: 184.8 s                      \n",
      "Loss: 8.34e-01 - Delta: -1.95e-03 - Trend: 9.57e-04\n",
      "Val Loss: 8.31e-01\n",
      "\n",
      "Epoch 9: [##################--]  93% - ETA:   13 s   Loss: 8.31e-01 (-3.56e-03)"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "BSM_eff = {'ep': []}\n",
    "for n in dataset.BSM_names:\n",
    "    BSM_eff[n] = []\n",
    "\n",
    "loss_history = {'train': [], 'val': [], 'val_feat': []}\n",
    "optimizer.zero_grad()\n",
    "try:\n",
    "    for epoch in range(max_epochs):\n",
    "        batch_loss = []\n",
    "\n",
    "        #### ---- Training ---- ####\n",
    "        model.train()\n",
    "        dataset.charge(dataset.SMMix_train)\n",
    "        train_data_iter = torch.utils.data.DataLoader(dataset, **training_params)\n",
    "        pb = ProgressBar(len(train_data_iter), percentPrecision=5, headLabel='Epoch {}: '.format(epoch))\n",
    "        for local_x, _ in train_data_iter:\n",
    "            if model.onGPU:\n",
    "                local_x = local_x.cuda(model.N_GPU)\n",
    "\n",
    "            x_prime = model(local_x)        \n",
    "            loss, _ = criterion(local_x, x_prime)\n",
    "            if np.isnan(loss.item()) or np.isinf(loss.item()):\n",
    "                print('Invalid training loss!!!')\n",
    "                raise NameError('LossNAN')\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            tail_label = 'Loss: {:2.2e}'.format(loss.item())\n",
    "            if len(loss_history['train']) > 0:\n",
    "                tail_label += ' ({:2.2e})'.format(loss.item() - loss_history['train'][-1][-1])\n",
    "            pb.show(len(batch_loss)-1, tail_label=tail_label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "#         aux_loss = 0\n",
    "#         N_batches = 0\n",
    "#         for local_x, _ in train_data_iter:\n",
    "#             if model.onGPU:\n",
    "#                 local_x = local_x.cuda(model.N_GPU)\n",
    "#             x_prime = model(local_x)\n",
    "#             loss, _ = criterion(local_x, x_prime)\n",
    "#             aux_loss += loss.item()\n",
    "#             N_batches += 1\n",
    "#         batch_loss.append(aux_loss/N_batches)\n",
    "\n",
    "        printout = 'Loss: {:2.2e}'.format(batch_loss[-1])\n",
    "        if len(loss_history['train']) > 0:\n",
    "            printout += ' - Delta: {:2.2e}'.format(batch_loss[-1] - loss_history['train'][-1][-1])\n",
    "        if len(loss_history['train']) > 1:\n",
    "            d2L_de2 = batch_loss[-1] - 2*loss_history['train'][-1][-1] + loss_history['train'][-2][-1]\n",
    "            printout +=' - Trend: {:2.2e}'.format(d2L_de2)\n",
    "        print(printout)\n",
    "\n",
    "        loss_history['train'].append(batch_loss)\n",
    "\n",
    "        #### ---- Validation ---- ####\n",
    "        dataset.charge(dataset.SMMix_val)\n",
    "        val_data_iter = torch.utils.data.DataLoader(dataset, **eval_params)\n",
    "        aux_loss = 0\n",
    "#         aux_feat = 0\n",
    "        N_batches = 0\n",
    "        for local_x, _ in val_data_iter:\n",
    "            if model.onGPU:\n",
    "                local_x = local_x.cuda(model.N_GPU)\n",
    "            x_prime = model(local_x)\n",
    "            loss, NLL_feat = criterion(local_x, x_prime)\n",
    "            if np.isnan(loss.item()) or np.isinf(loss.item()):\n",
    "                print('Invalid validation loss!!!')\n",
    "                raise NameError('LossNAN')\n",
    "            aux_loss += loss.item()\n",
    "#             aux_feat += NLL_feat\n",
    "            N_batches += 1\n",
    "        loss_history['val'].append(aux_loss/N_batches)\n",
    "#         loss_history['val_feat'].append(aux_feat/N_batches)\n",
    "        printout = 'Val Loss: {:2.2e}'.format(loss_history['val'][-1])\n",
    "#         printout += 'Cat:{:.2f}'.format(loss_history['val_feat'][-1])\n",
    "        print(printout)\n",
    "        if epoch > 0:\n",
    "            if loss_history['val'][-1] < np.min(loss_history['val']):\n",
    "                print('[INFO]: Saving best model')\n",
    "                torch.save(model.state_dict(), 'data/model_state_dict_dAE_v'+AEversion+'_best.pkl')\n",
    "\n",
    "        print('')\n",
    "        if not earlyStopping.check(loss_history['val'][-1]):\n",
    "            break\n",
    "\n",
    "        scheduler.step(batch_loss[-1])\n",
    "        \n",
    "        #### ---- Periodic save model ---- ####\n",
    "        if False and epoch%50 == 0:\n",
    "            torch.save(model.state_dict(), 'data/model_state_dict_dAE_v'+AEversion+'_epoch{}.pkl'.format(epoch))\n",
    "\n",
    "        #### ---- Anomaly Detection monitor ---- ####\n",
    "        if False and epoch%10 == 0:\n",
    "            print('------------ Anomaly Detection monitor ------------')\n",
    "            BSM_eff['ep'].append(epoch)\n",
    "            dataset.loss['SMMix'] = np.zeros((0))\n",
    "\n",
    "            pb = ProgressBar(len(val_data_iter), percentPrecision=5, headLabel='SM Mix: ')\n",
    "            for i, (local_x, _) in enumerate(val_data_iter):\n",
    "                    pb.show(i)\n",
    "                    if model.onGPU:\n",
    "                        local_x = local_x.cuda(model.N_GPU)\n",
    "\n",
    "                    x_prime = model(local_x)\n",
    "                    loss = criterion(local_x, x_prime, 'none').cpu().detach().numpy()\n",
    "                    dataset.loss['SMMix'] = np.concatenate((dataset.loss['SMMix'], loss))\n",
    "\n",
    "            p_SM = np.logspace(base=10, start=-5, stop=-3, num=3)\n",
    "            if not 'p_SM' in BSM_eff.keys():\n",
    "                BSM_eff['p_SM'] = p_SM\n",
    "            q_SM = np.quantile(dataset.loss['SMMix'], 1-p_SM)\n",
    "\n",
    "            table = PrettyTable(['SM Mix'] + list(map(lambda x: '{:1.2e}'.format(x), p_SM)))\n",
    "\n",
    "            for n in dataset.BSM_names:\n",
    "                dataset.loss[n] = np.zeros((0))\n",
    "\n",
    "                dataset.charge(dataset.valSamples[n])\n",
    "                data_iter = torch.utils.data.DataLoader(dataset, **eval_params)\n",
    "                pb = ProgressBar(len(data_iter), percentPrecision=5, headLabel=n+': ')\n",
    "                for i, (local_x, _) in enumerate(data_iter):\n",
    "                    pb.show(i)\n",
    "                    if model.onGPU:\n",
    "                        local_x = local_x.cuda(model.N_GPU)\n",
    "\n",
    "                    x_prime = model(local_x)\n",
    "                    loss = criterion(local_x, x_prime, 'none').cpu().detach().numpy()\n",
    "                    dataset.loss[n] = np.concatenate((dataset.loss[n], loss))\n",
    "\n",
    "                out = dataset.loss[n] > np.atleast_2d(q_SM).T\n",
    "                p_BSM = np.float64(np.sum(out, axis=1, dtype=np.float128)/dataset.loss[n].shape[0])\n",
    "                BSM_eff[n].append(p_BSM)\n",
    "\n",
    "                table.add_row([n] + list(map(lambda x: '{:1.2e}'.format(x), p_BSM)))\n",
    "            print(table)                \n",
    "            print('---------------------------------------------------\\n\\n')\n",
    "\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), 'data/model_state_dict_dAE_v'+AEversion+'.pkl');\n",
    "except NameError:\n",
    "    if epoch > 0:\n",
    "        print ('\\n\\nModel ended up nan. Recovering best model\\n')\n",
    "        model.load_state_dict(torch.load('data/model_state_dict_dAE_v'+AEversion+'_best.pkl'))\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T22:34:06.116602Z",
     "start_time": "2019-07-17T22:34:05.627926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_history['train'] = np.array(loss_history['train'])\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "f = plt.figure(figsize=(12,8))\n",
    "\n",
    "train_loss_flat = loss_history['train'].flatten()\n",
    "x = np.arange(1, train_loss_flat.shape[0]+1) * float(loss_history['train'].shape[0])/train_loss_flat.shape[0]\n",
    "plt.plot(x, train_loss_flat, '-', alpha=0.2, color='darkorange')\n",
    "\n",
    "x = np.arange(1, loss_history['train'].shape[0]+1)\n",
    "plt.plot(x, loss_history['train'][:,-1], 'o--', label='Train', color='darkorange')\n",
    "plt.plot(x, loss_history['val'], '*', label='Validatation', color='darkmagenta')\n",
    "\n",
    "# lval_feat = np.array(loss_history['val_feat'])\n",
    "# plt.plot(x, lval_feat[:,0], '--.', label='NLL $\\eta$', color='g')\n",
    "# plt.plot(x, lval_feat[:,1], '--.', label='NLL $\\phi$', color='b')\n",
    "# plt.plot(x, lval_feat[:,2], '--.', label='NLL charge-ID cat', color='k')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "# plt.yscale('log')\n",
    "plt.ylim(-5, 5)\n",
    "\n",
    "f.savefig('plots/TrainingHistory_dAE_v'+AEversion+'.png')\n",
    "\n",
    "f = open('data/TrainingHistory_dAE_v'+AEversion+'.pkl', 'wb')\n",
    "pickle.dump(loss_history, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T22:34:12.250532Z",
     "start_time": "2019-07-17T22:34:12.247995Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "# f, ax_arr = plt.subplots(2,2, figsize=(12,12))\n",
    "# styles = ['-', '--', ':']\n",
    "# x = BSM_eff['ep']\n",
    "# for i, n in enumerate(dataset.BSM_names):  \n",
    "#     ax = ax_arr[int(i/2),i%2]\n",
    "    \n",
    "#     BSM_eff[n] = np.array(BSM_eff[n])\n",
    "    \n",
    "#     for j in range(BSM_eff['p_SM'].shape[0]):\n",
    "# #         ax.plot(x, len(x)*[BSM_eff['p_SM'][j]], color='gray', lw=2, linestyle=styles[j])\n",
    "#         ax.plot(x, BSM_eff[n][:,j], \n",
    "#                 color=dataset.process_colors[n], lw=3, linestyle=styles[j], \n",
    "#                 label=dataset.process_labels[n] + ' @ $\\epsilon_{{SM}} = {:1.0e}$'.format(BSM_eff['p_SM'][j]))\n",
    "        \n",
    "#     ax.set_xlim([0, x[-1]+1])\n",
    "# #     ax.set_ylim([1e-6, 5])\n",
    "#     ax.set_xlabel('Epoch')\n",
    "#     ax.set_ylabel('Efficiency')\n",
    "#     ax.set_title('')\n",
    "#     ax.set_yscale('log')\n",
    "#     ax.grid()\n",
    "    \n",
    "#     ax.legend(loc='best')\n",
    "    \n",
    "# f.tight_layout()\n",
    "\n",
    "# f = open('data/AnomalyDetectionHistory_dAE_v'+AEversion+'.pkl', 'wb')\n",
    "# pickle.dump(BSM_eff, f)\n",
    "# f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T22:34:12.462680Z",
     "start_time": "2019-07-17T22:34:12.460641Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('data/model_state_dict_dAE_v'+AEversion+'_epoch400.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T22:34:13.014321Z",
     "start_time": "2019-07-17T22:34:12.980065Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.charge(dataset.SMMix_val)\n",
    "x = dataset.inputs\n",
    "model.eval()\n",
    "if model.onGPU:\n",
    "    x_prime = model(torch.from_numpy(x[:10000]).cuda(model.N_GPU)).cpu().detach().numpy()\n",
    "    z = model.encode(torch.from_numpy(x[:10000]).cuda(model.N_GPU)).cpu().detach().numpy()\n",
    "else:\n",
    "    x_prime = model(torch.from_numpy(x[:10000])).cpu().detach().numpy()\n",
    "    z = model.encode(torch.from_numpy(x[:10000])).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T22:34:13.818910Z",
     "start_time": "2019-07-17T22:34:13.816791Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(z.shape[1]):\n",
    "#     x_aux = z[:,i]\n",
    "#     f = plt.figure(i)\n",
    "#     r = (np.min(x_aux), np.max(x_aux))\n",
    "#     plt.hist(x_aux, bins=20, range=r, alpha=0.4, density=True)\n",
    "#     plt.xlabel('$z_{{{}}}$'.format(i))\n",
    "#     dnd.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-17T22:34:17.428134Z",
     "start_time": "2019-07-17T22:34:15.008025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00933333, 0.00644   , 0.01030667, 0.0075    , 0.15011   ,\n",
       "        0.15734667, 0.13958667, 0.51937667]),\n",
       " array([-0.5,  0.5,  1.5,  2.5,  3.5,  4.5,  5.5,  6.5,  7.5]),\n",
       " <a list of 8 Patch objects>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tc = np.argmax(x[:,:,3:], axis=-1).flatten()\n",
    "pc = np.argmax(x_prime[:,:,:], axis=-1).flatten()\n",
    "\n",
    "plt.hist(tc, bins=np.arange(-0.5, 8.5, 1), alpha=0.4, density=True)\n",
    "plt.hist(pc, bins=np.arange(-0.5, 8.5, 1), alpha=0.4, density=True)\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.229Z"
    }
   },
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.231Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(x.shape[2]):\n",
    "    x_aux = x[:,:,i].flatten()\n",
    "    if i < 3:\n",
    "        continue\n",
    "        xp_aux = x_prime[:,:,i].flatten()\n",
    "    elif i==3:\n",
    "        xp_aux = np.argmax(x_prime[:,:,6:9], axis=2)\n",
    "        xp_aux = xp_aux.flatten() - 1\n",
    "    elif i==4:\n",
    "        xp_aux = np.argmax(x_prime[:,:,9:14], axis=2).flatten()\n",
    "        \n",
    "    f = plt.figure(i)\n",
    "    r = (min(np.min(x_aux), np.min(xp_aux)), max(np.max(x_aux), np.max(xp_aux)))\n",
    "    if i == 0:\n",
    "        r = (0,10)\n",
    "    plt.hist(x_aux, bins=31, range=r, alpha=0.4, density=True)\n",
    "    plt.hist(xp_aux, bins=31, range=r, alpha=0.4, density=True)\n",
    "    plt.xlabel('Particles ' + dataset.feature_names[i])\n",
    "#     plt.yscale('log')\n",
    "    dnd.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.232Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.loadValidationSamples('SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.234Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for n in list(dataset.valSamples.keys()) + ['SMMix']:\n",
    "    dataset.loss[n] = np.zeros((0))\n",
    "    if n == 'SMMix':\n",
    "        dataset.charge(dataset.SMMix_val)\n",
    "    else:\n",
    "        dataset.charge(dataset.valSamples[n])\n",
    "    \n",
    "    data_iter = torch.utils.data.DataLoader(dataset, **eval_params)\n",
    "    pb = ProgressBar(len(data_iter), percentPrecision=5, headLabel=n+': ')\n",
    "    for i, (local_x, _) in enumerate(data_iter):\n",
    "        pb.show(i)\n",
    "        if model.onGPU:\n",
    "            local_x = local_x.cuda(model.N_GPU)\n",
    "            \n",
    "        x_prime = model(local_x)\n",
    "        loss = criterion(local_x, x_prime, 'none').cpu().detach().numpy()\n",
    "        dataset.loss[n] = np.concatenate((dataset.loss[n], loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.235Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ra = np.array(list(map(lambda x: [np.min(x), np.quantile(x, 1-1e-3)], dataset.loss.values())))\n",
    "r = (np.min(ra[:,0]), np.max(ra[:,1]))\n",
    "\n",
    "for n in ['Ato4l','SMMix']:\n",
    "    plt.hist(dataset.loss[n], bins=31, range=r,\n",
    "             density=True,\n",
    "             color=dataset.process_colors[n], \n",
    "             alpha=0.3, \n",
    "             label=dataset.process_labels[n])\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.237Z"
    }
   },
   "outputs": [],
   "source": [
    "dic_ROC = createROC_curve(dataset)\n",
    "pickle.dump(dic_ROC, open('data/dAE_v{}_ROC_dic.pkl'.format(AEversion), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.238Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_ROC, ax_arr = plt.subplots(2,2, figsize=(12,12))\n",
    "for i, n in enumerate(dataset.BSM_names):\n",
    "    f = open('../data/HLFref1811-10276_loss/VAE_all-in-one_v71_ROC1_dict_{}.pkl'.format(n), 'br')\n",
    "    dRef = pickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    \n",
    "    ax = ax_arr[int(i/2),i%2]\n",
    "    ax.plot(dRef[b'eff_SM'], dRef[b'eff_BSM'], label=dataset.process_labels[n] + ' HLF',\n",
    "            linestyle='--', lw=3, color=dataset.process_colors[n])\n",
    "    ax.plot(dic_ROC[n]['eff_SM'], dic_ROC[n]['eff_BSM'], label=dataset.process_labels[n] + ' PF',\n",
    "            linestyle='-', lw=3, color=dataset.process_colors[n])\n",
    "    ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle=':')\n",
    "    ax.set_xlim([1e-6, 1.0])\n",
    "    ax.set_ylim([1e-6, 1.05])\n",
    "    ax.set_xlabel('SM efficiency')\n",
    "    ax.set_ylabel('BSM efficiency')\n",
    "    ax.set_title('')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid()\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "f_ROC.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent dimension clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.240Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.241Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.encoded = {}\n",
    "\n",
    "for n in dataset.BSM_names:    \n",
    "    dataset.charge(dataset.valSamples[n][:10000])\n",
    "    x_in = torch.Tensor(dataset.inputs)\n",
    "    if model.onGPU:\n",
    "        x_in = x_in.cuda(model.N_GPU)\n",
    "    dataset.encoded[n] = model.encode(x_in).cpu().detach().numpy()\n",
    "    \n",
    "dataset.charge(dataset.SMMix_val[:10000])\n",
    "x_in = torch.Tensor(dataset.inputs)\n",
    "if model.onGPU:\n",
    "        x_in = x_in.cuda(model.N_GPU)\n",
    "dataset.encoded['SMMix'] = model.encode(x_in).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.243Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_max = 1000 #np.min(list(map(lambda x: x.shape[0], dataset.encoded.values())))\n",
    "z_dset = np.zeros((0, model.Nk))\n",
    "\n",
    "for n in dataset.encoded.keys():\n",
    "    z_dset = np.concatenate((z_dset, dataset.encoded[n][:idx_max]))\n",
    "    \n",
    "z_embedded = TSNE(n_components=2).fit_transform(z_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-17T15:37:00.244Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8,8))\n",
    "\n",
    "for i, n in enumerate(dataset.encoded.keys()):\n",
    "#     if not n in ['Ato4l', 'SMMix']: continue\n",
    "    aux_z = z_embedded[i*idx_max: (i+1)*idx_max]\n",
    "    plt.plot(aux_z[:,0], aux_z[:,1], \n",
    "             'o',\n",
    "             color=dataset.process_colors[n], \n",
    "             mfc='none',\n",
    "             label=dataset.process_labels[n])\n",
    "    \n",
    "plt.xlabel('Embedded 0')\n",
    "plt.ylabel('Embedded 1')\n",
    "plt.legend(loc='best')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
