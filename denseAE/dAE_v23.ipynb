{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 20 with Elu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:10.609854Z",
     "start_time": "2019-07-18T13:43:10.607012Z"
    }
   },
   "outputs": [],
   "source": [
    "AEversion = '23'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:11.130879Z",
     "start_time": "2019-07-18T13:43:10.765851Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os, sys, pickle\n",
    "from prettytable import PrettyTable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "%autosave 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:11.360129Z",
     "start_time": "2019-07-18T13:43:11.132542Z"
    },
    "code_folding": [
     1,
     3
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mimperium-sm.hep.caltech.edu\u001b[m  Thu Jul 18 06:43:11 2019\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 22'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  466\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m455M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[1m\u001b[31m 51'C\u001b[m, \u001b[32m 15 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 4446\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m4435M\u001b[m)\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 23'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "import gpustat\n",
    "try:\n",
    "    gpustat.print_gpustat()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:11.717374Z",
     "start_time": "2019-07-18T13:43:11.361914Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:11.925136Z",
     "start_time": "2019-07-18T13:43:11.897672Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append('../lib')\n",
    "from progressBar import ProgressBar\n",
    "from utils import EarlyStopping, createROC_curve, ELU_ProbNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:12.131949Z",
     "start_time": "2019-07-18T13:43:12.129618Z"
    }
   },
   "outputs": [],
   "source": [
    "dnd = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:24.789207Z",
     "start_time": "2019-07-18T13:43:24.773212Z"
    }
   },
   "outputs": [],
   "source": [
    "from dataLoaders import ParticleDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:43:25.009819Z",
     "start_time": "2019-07-18T13:43:25.006436Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = ParticleDataset(template='../data/20190717_50part_PtOrder_v3/{}.npy', N_part=10, N_features=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:47.422756Z",
     "start_time": "2019-07-18T13:43:54.929020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching Wlnu\n",
      "Fetching qcd\n",
      "Fetching Zll\n",
      "Fetching ttbar\n",
      "Expected 1.00M train\n",
      "Expected 1.00M val\n",
      "\n",
      "Loading Wlnu\n",
      "Loading qcd\n",
      "Loading Zll\n",
      "Loading ttbar\n",
      "+--------+----------+-------+------+\n",
      "| Sample | Evts tot | Train | Val  |\n",
      "+--------+----------+-------+------+\n",
      "|  Wlnu  |  5618k   |  592k | 592k |\n",
      "|  qcd   |  1166k   |  338k | 338k |\n",
      "|  Zll   |  1777k   |  67k  | 67k  |\n",
      "| ttbar  |  6542k   |   3k  |  3k  |\n",
      "+--------+----------+-------+------+\n",
      "Tot training 1.00 M\n",
      "Tot val 1.00 M\n"
     ]
    }
   ],
   "source": [
    "dataset.loadTrainSM(N_train_max=1e6)\n",
    "dataset.charge(dataset.SMMix_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:52.806156Z",
     "start_time": "2019-07-18T13:45:47.424589Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Ato4l (47.7k)\n",
      "Loading leptoquark (273.6k)\n",
      "Loading hToTauTau (685.8k)\n",
      "Loading hChToTauNu (339.0k)\n"
     ]
    }
   ],
   "source": [
    "dataset.loadValidationSamples('BSM', N_max=1000000000000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:52.828665Z",
     "start_time": "2019-07-18T13:45:52.808193Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class AEDenseNet(nn.Module):\n",
    "    def __init__(self, N_part, N_features, dim_hidden, dim_latent, verbose = False):\n",
    "        super(AEDenseNet, self).__init__()\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.No = N_part\n",
    "        self.p = N_features\n",
    "        self.Nk = dim_latent\n",
    "        \n",
    "        self.encoder_modules = nn.ModuleDict({\n",
    "            'PhiE': self.build_dense(dim_in=self.p*self.No,\n",
    "                                   dim_out=self.Nk,\n",
    "                                   dim_hidden=dim_hidden)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        self.decoder_modules = nn.ModuleDict({\n",
    "            'PhiD': self.build_dense(dim_in=self.Nk,\n",
    "                                   dim_out=(self.p+3)*self.No,\n",
    "                                   dim_hidden=dim_hidden)\n",
    "        })\n",
    "        \n",
    "        \n",
    "        self.onGPU = False\n",
    "          \n",
    "    def build_dense(self, dim_in, dim_out, dim_hidden=0):\n",
    "        if dim_hidden:\n",
    "            net = nn.Sequential(\n",
    "                                nn.Linear(dim_in, dim_hidden),\n",
    "                                nn.BatchNorm1d(dim_hidden, affine=False),\n",
    "                                nn.ELU(),\n",
    "                                nn.Linear(dim_hidden, dim_hidden),\n",
    "                                nn.BatchNorm1d(dim_hidden, affine=False),\n",
    "                                nn.ELU(),\n",
    "                                nn.Linear(dim_hidden, dim_out),\n",
    "                                nn.BatchNorm1d(dim_out, affine=False),\n",
    "                              )\n",
    "        else:\n",
    "            d_avg = int(0.5*(dim_in + dim_out))\n",
    "            net = nn.Sequential(\n",
    "                                nn.Linear(dim_in, d_avg),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(d_avg, dim_out),\n",
    "                              )\n",
    "        return net\n",
    "        \n",
    "    def encode(self, x):\n",
    "        z = self.encoder_modules['PhiE'](x.contiguous().view(-1, self.p*self.No))\n",
    "#         z = F.relu(z_raw)\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):\n",
    "        x_raw = self.decoder_modules['PhiD'](z).view(-1, self.No, self.p+3)\n",
    "        \n",
    "        # --- Formatting x ----\n",
    "        # pt\n",
    "        pt = 1. + F.elu(x_raw[:,:,0]).view(-1, self.No, 1)\n",
    "        sig_pt = 1. + 1e-6 + F.elu(x_raw[:,:,1]).view(-1, self.No, 1)\n",
    "        # eta\n",
    "        eta = F.hardtanh(x_raw[:,:,2], min_val=-5, max_val=5).view(-1, self.No, 1)\n",
    "        sig_eta = 1. + 1e-6 + F.elu(x_raw[:,:,3]).view(-1, self.No, 1)\n",
    "        # phi\n",
    "#         phi = torch.fmod(torch.abs(x_raw[:,:,4]), 6.2831853072).view(-1, self.No, 1) - 3.14159265359\n",
    "        phi = 3.14159265359*torch.sin(x_raw[:,:,4]).view(-1, self.No, 1)\n",
    "        sig_phi = 1. + 1e-6 + F.elu(x_raw[:,:,5]).view(-1, self.No, 1)\n",
    "        \n",
    "        # charge & pId category\n",
    "#         cpId_cat = F.softmax(x_raw[:,:,6:], dim=-1)\n",
    "        cpId_cat = ELU_ProbNorm(x_raw[:,:,6:], dim=-1)\n",
    "    \n",
    "        x = torch.cat((pt, eta, phi, sig_pt, sig_eta, sig_phi, cpId_cat), 2)\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        x_prime = self.decode(z)\n",
    "        return x_prime\n",
    "    \n",
    "    def initWeights(self):\n",
    "        def weights_init(M):\n",
    "            if hasattr(M, 'weight'):\n",
    "                nn.init.xavier_normal_(M.weight.data)\n",
    "        \n",
    "        self.apply(weights_init)\n",
    "    \n",
    "    def useGPU(self, N_GPU=1):\n",
    "        if torch.cuda.is_available():\n",
    "            print('Current device: {} ({} available)'.format(torch.cuda.current_device(), \n",
    "                                                             torch.cuda.device_count()))\n",
    "            os.environ['CUDA_VISIBLE_DEVICES'] = str(N_GPU)\n",
    "            self.N_GPU = N_GPU\n",
    "            torch.cuda.empty_cache()\n",
    "            self.cuda(N_GPU)\n",
    "            gpustat.print_gpustat()\n",
    "            \n",
    "            self.onGPU = True\n",
    "        else: \n",
    "            print('GPU not available')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:52.847178Z",
     "start_time": "2019-07-18T13:45:52.830369Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AEDenseNet(\n",
      "  (encoder_modules): ModuleDict(\n",
      "    (PhiE): Sequential(\n",
      "      (0): Linear(in_features=330, out_features=500, bias=True)\n",
      "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): Linear(in_features=500, out_features=500, bias=True)\n",
      "      (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=500, out_features=40, bias=True)\n",
      "      (7): BatchNorm1d(40, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder_modules): ModuleDict(\n",
      "    (PhiD): Sequential(\n",
      "      (0): Linear(in_features=40, out_features=500, bias=True)\n",
      "      (1): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (2): ELU(alpha=1.0)\n",
      "      (3): Linear(in_features=500, out_features=500, bias=True)\n",
      "      (4): BatchNorm1d(500, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "      (5): ELU(alpha=1.0)\n",
      "      (6): Linear(in_features=500, out_features=420, bias=True)\n",
      "      (7): BatchNorm1d(420, eps=1e-05, momentum=0.1, affine=False, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "Trainable parameters: 917460\n"
     ]
    }
   ],
   "source": [
    "Latent_dimension = 40\n",
    "Hidden_dimension = 500\n",
    "\n",
    "model = AEDenseNet(\n",
    "                   N_part=dataset.inputs.shape[1],\n",
    "                   N_features=dataset.inputs.shape[2],\n",
    "                   dim_hidden=Hidden_dimension,\n",
    "                   dim_latent=Latent_dimension\n",
    "                  )\n",
    "\n",
    "print(model)\n",
    "trainablePars = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print('\\nTrainable parameters:', trainablePars)\n",
    "\n",
    "# model.initWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:56.672250Z",
     "start_time": "2019-07-18T13:45:52.848653Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current device: 0 (8 available)\n",
      "\u001b[1m\u001b[37mimperium-sm.hep.caltech.edu\u001b[m  Thu Jul 18 06:45:56 2019\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 23'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  466\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m455M\u001b[m)\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[1m\u001b[31m 50'C\u001b[m, \u001b[32m 15 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 4446\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m4435M\u001b[m)\n",
      "\u001b[36m[2]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   10\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[3]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 23'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[4]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 26'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[5]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 24'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[6]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 25'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m   11\u001b[m / \u001b[33m 8119\u001b[m MB |\n",
      "\u001b[36m[7]\u001b[m \u001b[34mGeForce GTX 1080\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  4 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m  470\u001b[m / \u001b[33m 8119\u001b[m MB | \u001b[1m\u001b[30mocerri\u001b[m(\u001b[33m459M\u001b[m)\n"
     ]
    }
   ],
   "source": [
    "model.useGPU(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:56.687636Z",
     "start_time": "2019-07-18T13:45:56.673839Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def criterion(x_in, x_out, reduction='mean'):\n",
    "    sigma = x_out[:,:,3:6]\n",
    "    \n",
    "    # Pt\n",
    "    NLL_pt = 0.5*torch.pow((x_in[:,:,0] - x_out[:,:,0])/ sigma[:,:,0], 2) + torch.log(sigma[:,:,0])\n",
    "    NLL_pt = NLL_pt.view(-1, x_in.shape[1], 1)\n",
    "    \n",
    "    # Eta\n",
    "    aux = sigma[:,:,1]*np.sqrt(2)\n",
    "    Norm = 0.5*(torch.erf(5./aux) - torch.erf(-5./aux))\n",
    "    NLL_eta = 0.5*torch.pow((x_in[:,:,1] - x_out[:,:,1])/ sigma[:,:,1], 2) + torch.log(Norm)\n",
    "    NLL_eta = NLL_eta.view(-1, x_in.shape[1], 1)\n",
    "\n",
    "    # Phi\n",
    "    dphi = x_in[:,:,2] - x_out[:,:,2]\n",
    "    dphi = torch.where(dphi>np.pi, dphi-2*np.pi, torch.where(dphi<-np.pi, dphi+2*np.pi, dphi))\n",
    "    \n",
    "    aux = sigma[:,:,2]*np.sqrt(2)\n",
    "    Norm = 0.5*(torch.erf(np.pi/aux) - torch.erf(-np.pi/aux))\n",
    "    \n",
    "    NLL_phi = 0.5*torch.pow((dphi)/ sigma[:,:,2], 2) + torch.log(Norm)\n",
    "    NLL_phi = NLL_phi.view(-1, x_in.shape[1], 1)\n",
    "    \n",
    "    # Cat cross entropy charge-pId\n",
    "    log_p = torch.log(x_out[:,:,6:]).view(-1, 8)\n",
    "    true_cat = torch.argmax(x_in[:,:,3:], dim=2)\n",
    "    NLL_cat = F.nll_loss(log_p, true_cat.view(-1).long(), reduction='none').view(-1, x_in.shape[1], 1)\n",
    "    \n",
    "    NLL_tot = torch.cat((NLL_pt, NLL_eta, NLL_phi, NLL_cat), 2)\n",
    "    NLL_perEvent = torch.mean(NLL_tot, dim=1)\n",
    "    \n",
    "    if reduction == 'mean':\n",
    "        NLL_mean = torch.mean(NLL_perEvent, dim=0)\n",
    "        return torch.sum(NLL_mean), NLL_mean.cpu().detach().numpy()\n",
    "    elif reduction == 'none':\n",
    "        return torch.sum(NLL_perEvent, dim=1)\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:56.692270Z",
     "start_time": "2019-07-18T13:45:56.689107Z"
    },
    "code_folding": [
     0,
     7
    ]
   },
   "outputs": [],
   "source": [
    "training_params = {'batch_size': 1024,\n",
    "                   'shuffle': True,\n",
    "                   'num_workers': 1\n",
    "                  }\n",
    "\n",
    "max_epochs = 1000\n",
    "freq_AN_performance_check = 3\n",
    "freq_model_save = 3\n",
    "\n",
    "eval_params = {'batch_size': 50000,\n",
    "               'num_workers': 3\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:56.696791Z",
     "start_time": "2019-07-18T13:45:56.694484Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.autograd.set_detect_anomaly(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T13:45:56.702331Z",
     "start_time": "2019-07-18T13:45:56.698436Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "scheduler = ReduceLROnPlateau(optimizer, \n",
    "                              mode='min',\n",
    "                              factor=0.3,\n",
    "                              patience=3,\n",
    "                              verbose=1,\n",
    "                              threshold=1e-3,\n",
    "                              cooldown=2,\n",
    "                              min_lr=1e-7\n",
    "                             )\n",
    "\n",
    "# Early stopping\n",
    "earlyStopping = EarlyStopping(patient=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T14:16:29.843881Z",
     "start_time": "2019-07-18T13:45:56.703944Z"
    },
    "code_folding": [
     7
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: [####################]  100% - Tot. time: 82.8 s           \n",
      "Loss: 4.46e+00\n",
      "Val Loss: 4.46e+00 Pt:0.12 - Eta:1.20 - Phi:1.16 - Cat:1.98\n",
      "\n",
      "------------ Anomaly Detection monitor ------------\n",
      "SM Mix: [####################]  100% - Tot. time: 5.4 s\n",
      "Ato4l: [#]  100% - Tot. time: 0.0 s\n",
      "leptoquark: [######]  100% - Tot. time: 0.8 s\n",
      "hToTauTau: [##############]  100% - Tot. time: 3.1 s\n",
      "hChToTauNu: [#######]  100% - Tot. time: 1.2 s\n",
      "+------------+----------+----------+----------+\n",
      "|   SM Mix   | 1.00e-05 | 1.00e-04 | 1.00e-03 |\n",
      "+------------+----------+----------+----------+\n",
      "|   Ato4l    | 0.00e+00 | 3.35e-04 | 6.96e-03 |\n",
      "| leptoquark | 1.46e-05 | 2.59e-04 | 4.37e-03 |\n",
      "| hToTauTau  | 1.41e-04 | 1.10e-03 | 1.19e-02 |\n",
      "| hChToTauNu | 1.68e-04 | 1.36e-03 | 1.38e-02 |\n",
      "+------------+----------+----------+----------+\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 1: [####################]  100% - Tot. time: 82.0 s                       \n",
      "Loss: 3.90e+00 - Delta: -5.57e-01\n",
      "Val Loss: 3.91e+00 Pt:0.09 - Eta:0.79 - Phi:1.09 - Cat:1.93\n",
      "[INFO]: Saving best model\n",
      "\n",
      "Epoch 2: [####################]  100% - Tot. time: 81.2 s                       \n",
      "Loss: 3.75e+00 - Delta: -1.52e-01 - Trend: 4.05e-01\n",
      "Val Loss: 3.75e+00 Pt:0.09 - Eta:0.66 - Phi:1.07 - Cat:1.93\n",
      "[INFO]: Saving best model\n",
      "\n",
      "Epoch 3: [####################]  100% - Tot. time: 82.3 s                       \n",
      "Loss: 3.59e+00 - Delta: -1.60e-01 - Trend: -8.44e-03\n",
      "Val Loss: 3.59e+00 Pt:0.08 - Eta:0.54 - Phi:1.05 - Cat:1.93\n",
      "[INFO]: Saving best model\n",
      "\n",
      "------------ Anomaly Detection monitor ------------\n",
      "SM Mix: [####################]  100% - Tot. time: 5.5 s\n",
      "Ato4l: [#]  100% - Tot. time: 0.0 s\n",
      "leptoquark: [######]  100% - Tot. time: 0.8 s\n",
      "hToTauTau: [##############]  100% - Tot. time: 3.7 s\n",
      "hChToTauNu: [#######]  100% - Tot. time: 1.2 s\n",
      "+------------+----------+----------+----------+\n",
      "|   SM Mix   | 1.00e-05 | 1.00e-04 | 1.00e-03 |\n",
      "+------------+----------+----------+----------+\n",
      "|   Ato4l    | 4.19e-05 | 1.36e-03 | 1.46e-02 |\n",
      "| leptoquark | 6.94e-05 | 7.49e-04 | 1.06e-02 |\n",
      "| hToTauTau  | 6.77e-04 | 2.66e-03 | 2.49e-02 |\n",
      "| hChToTauNu | 1.35e-03 | 3.72e-03 | 3.18e-02 |\n",
      "+------------+----------+----------+----------+\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 4: [####################]  100% - Tot. time: 88.2 s                       \n",
      "Loss: 3.50e+00 - Delta: -9.46e-02 - Trend: 6.58e-02\n",
      "Val Loss: 3.50e+00 Pt:0.06 - Eta:0.49 - Phi:1.02 - Cat:1.93\n",
      "[INFO]: Saving best model\n",
      "\n",
      "Epoch 5: [####################]  100% - Tot. time: 87.4 s                       \n",
      "Loss: 3.50e+00 - Delta: -7.23e-04 - Trend: 9.39e-02\n",
      "Val Loss: 3.50e+00 Pt:0.06 - Eta:0.50 - Phi:1.03 - Cat:1.91\n",
      "[INFO]: Saving best model\n",
      "\n",
      "Epoch 6: [####################]  100% - Tot. time: 81.3 s                       \n",
      "Loss: 4.61e+00 - Delta: 1.11e+00 - Trend: 1.12e+00\n",
      "Val Loss: 4.61e+00 Pt:0.07 - Eta:1.35 - Phi:1.25 - Cat:1.94\n",
      "\n",
      "------------ Anomaly Detection monitor ------------\n",
      "SM Mix: [####################]  100% - Tot. time: 4.9 s\n",
      "Ato4l: [#]  100% - Tot. time: 0.0 s\n",
      "leptoquark: [######]  100% - Tot. time: 0.8 s\n",
      "hToTauTau: [##############]  100% - Tot. time: 3.3 s\n",
      "hChToTauNu: [#######]  100% - Tot. time: 1.3 s\n",
      "+------------+----------+----------+----------+\n",
      "|   SM Mix   | 1.00e-05 | 1.00e-04 | 1.00e-03 |\n",
      "+------------+----------+----------+----------+\n",
      "|   Ato4l    | 1.05e-04 | 5.87e-04 | 4.15e-03 |\n",
      "| leptoquark | 7.31e-06 | 9.87e-05 | 1.18e-03 |\n",
      "| hToTauTau  | 3.94e-05 | 2.65e-04 | 1.92e-03 |\n",
      "| hChToTauNu | 4.72e-05 | 2.57e-04 | 2.12e-03 |\n",
      "+------------+----------+----------+----------+\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 7: [####################]  100% - Tot. time: 82.7 s                       \n",
      "Loss: 7.11e+04 - Delta: 7.11e+04 - Trend: 7.11e+04\n",
      "Val Loss: 4.81e+04 Pt:0.05 - Eta:0.51 - Phi:48069.70 - Cat:1.92\n",
      "\n",
      "Epoch 8: [####################]  100% - Tot. time: 82.4 s                       \n",
      "Loss: 6.13e+00 - Delta: -7.11e+04 - Trend: -1.42e+05\n",
      "Val Loss: 3.73e+00 Pt:0.05 - Eta:0.48 - Phi:1.29 - Cat:1.91\n",
      "\n",
      "Epoch     8: reducing learning rate of group 0 to 3.0000e-04.\n",
      "Epoch 9: [####################]  100% - Tot. time: 84.5 s                       \n",
      "Loss: 3.41e+01 - Delta: 2.80e+01 - Trend: 7.12e+04\n",
      "Val Loss: 9.74e+01 Pt:0.05 - Eta:0.46 - Phi:95.01 - Cat:1.91\n",
      "\n",
      "------------ Anomaly Detection monitor ------------\n",
      "SM Mix: [####################]  100% - Tot. time: 5.1 s\n",
      "Ato4l: [#]  100% - Tot. time: 0.0 s\n",
      "leptoquark: [######]  100% - Tot. time: 0.8 s\n",
      "hToTauTau: [##############]  100% - Tot. time: 3.6 s\n",
      "hChToTauNu: [#######]  100% - Tot. time: 1.2 s\n",
      "+------------+----------+----------+----------+\n",
      "|   SM Mix   | 1.00e-05 | 1.00e-04 | 1.00e-03 |\n",
      "+------------+----------+----------+----------+\n",
      "|   Ato4l    | 6.29e-05 | 1.38e-03 | 1.71e-02 |\n",
      "| leptoquark | 8.77e-05 | 9.80e-04 | 7.38e-03 |\n",
      "| hToTauTau  | 9.24e-04 | 5.45e-03 | 2.07e-02 |\n",
      "| hChToTauNu | 1.84e-03 | 8.85e-03 | 2.78e-02 |\n",
      "+------------+----------+----------+----------+\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 10: [####################]  100% - Tot. time: 81.8 s                       \n",
      "Loss: 3.39e+00 - Delta: -3.07e+01 - Trend: -5.87e+01\n",
      "Val Loss: 3.39e+00 Pt:0.06 - Eta:0.45 - Phi:0.97 - Cat:1.90\n",
      "[INFO]: Saving best model\n",
      "\n",
      "Epoch 11: [####################]  100% - Tot. time: 88.6 s                       \n",
      "Loss: 4.92e+03 - Delta: 4.92e+03 - Trend: 4.95e+03\n",
      "Val Loss: 5.99e+02 Pt:595.42 - Eta:0.46 - Phi:0.97 - Cat:1.90\n",
      "\n",
      "Epoch 12: [####################]  100% - Tot. time: 81.1 s                       \n",
      "Loss: 3.34e+00 - Delta: -4.92e+03 - Trend: -9.83e+03\n",
      "Val Loss: 3.35e+00 Pt:0.04 - Eta:0.45 - Phi:0.97 - Cat:1.89\n",
      "[INFO]: Saving best model\n",
      "\n",
      "------------ Anomaly Detection monitor ------------\n",
      "SM Mix: [####################]  100% - Tot. time: 5.8 s\n",
      "Ato4l: [#]  100% - Tot. time: 0.0 s\n",
      "leptoquark: [######]  100% - Tot. time: 0.9 s\n",
      "hToTauTau: [##############]  100% - Tot. time: 3.5 s\n",
      "hChToTauNu: [#######]  100% - Tot. time: 1.2 s\n",
      "+------------+----------+----------+----------+\n",
      "|   SM Mix   | 1.00e-05 | 1.00e-04 | 1.00e-03 |\n",
      "+------------+----------+----------+----------+\n",
      "|   Ato4l    | 8.38e-05 | 2.47e-03 | 1.95e-02 |\n",
      "| leptoquark | 9.14e-05 | 8.81e-04 | 7.07e-03 |\n",
      "| hToTauTau  | 8.05e-04 | 3.15e-03 | 1.78e-02 |\n",
      "| hChToTauNu | 1.55e-03 | 4.25e-03 | 2.20e-02 |\n",
      "+------------+----------+----------+----------+\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 13: [####################]  100% - Tot. time: 80.6 s                       \n",
      "Loss: 1.72e+04 - Delta: 1.72e+04 - Trend: 2.21e+04\n",
      "Val Loss: 1.34e+03 Pt:1341.34 - Eta:0.45 - Phi:0.95 - Cat:1.89\n",
      "\n",
      "Epoch 14: [####################]  100% - Tot. time: 81.9 s                       \n",
      "Loss: 4.44e+02 - Delta: -1.68e+04 - Trend: -3.40e+04\n",
      "Val Loss: 2.94e+01 Pt:26.09 - Eta:0.44 - Phi:0.95 - Cat:1.88\n",
      "\n",
      "Epoch 15: [####################]  100% - Tot. time: 80.7 s                       \n",
      "Loss: 9.99e+00 - Delta: -4.34e+02 - Trend: 1.63e+04\n",
      "Val Loss: 4.05e+00 Pt:0.82 - Eta:0.43 - Phi:0.91 - Cat:1.88\n",
      "\n",
      "------------ Anomaly Detection monitor ------------\n",
      "SM Mix: [####################]  100% - Tot. time: 5.5 s\n",
      "Ato4l: [#]  100% - Tot. time: 0.0 s\n",
      "leptoquark: [######]  100% - Tot. time: 0.9 s\n",
      "hToTauTau: [##############]  100% - Tot. time: 3.5 s\n",
      "hChToTauNu: [#######]  100% - Tot. time: 1.2 s\n",
      "+------------+----------+----------+----------+\n",
      "|   SM Mix   | 1.00e-05 | 1.00e-04 | 1.00e-03 |\n",
      "+------------+----------+----------+----------+\n",
      "|   Ato4l    | 4.19e-05 | 2.03e-03 | 1.88e-02 |\n",
      "| leptoquark | 9.87e-05 | 8.52e-04 | 6.25e-03 |\n",
      "| hToTauTau  | 9.52e-04 | 4.10e-03 | 1.73e-02 |\n",
      "| hChToTauNu | 1.86e-03 | 6.19e-03 | 2.29e-02 |\n",
      "+------------+----------+----------+----------+\n",
      "---------------------------------------------------\n",
      "\n",
      "\n",
      "Epoch 16: [####################]  100% - Tot. time: 82.7 s                       \n",
      "Loss: 1.54e+05 - Delta: 1.54e+05 - Trend: 1.54e+05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-b965a9b4f79b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0maux_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mN_batches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mlocal_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_data_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monGPU\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0mlocal_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocal_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_GPU\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/PartAN/lib/python3.7/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "BSM_eff = {'ep': []}\n",
    "for n in dataset.BSM_names:\n",
    "    BSM_eff[n] = []\n",
    "\n",
    "loss_history = {'train': [], 'val': [], 'val_feat': []}\n",
    "optimizer.zero_grad()\n",
    "try:\n",
    "    for epoch in range(max_epochs):\n",
    "        batch_loss = []\n",
    "\n",
    "        #### ---- Training ---- ####\n",
    "        model.train()\n",
    "        dataset.charge(dataset.SMMix_train)\n",
    "        train_data_iter = torch.utils.data.DataLoader(dataset, **training_params)\n",
    "        pb = ProgressBar(len(train_data_iter), percentPrecision=5, headLabel='Epoch {}: '.format(epoch))\n",
    "        for local_x, _ in train_data_iter:\n",
    "            if model.onGPU:\n",
    "                local_x = local_x.cuda(model.N_GPU)\n",
    "\n",
    "            x_prime = model(local_x)        \n",
    "            loss, _ = criterion(local_x, x_prime)\n",
    "            if np.isnan(loss.item()) or np.isinf(loss.item()):\n",
    "                print('Invalid training loss!!!')\n",
    "                raise NameError('LossNAN')\n",
    "            batch_loss.append(loss.item())\n",
    "\n",
    "            tail_label = 'Loss: {:2.2e}'.format(loss.item())\n",
    "            if len(loss_history['train']) > 0:\n",
    "                tail_label += ' ({:2.2e})'.format(loss.item() - loss_history['train'][-1][-1])\n",
    "            pb.show(len(batch_loss)-1, tail_label=tail_label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        model.eval()\n",
    "        aux_loss = 0\n",
    "        N_batches = 0\n",
    "        train_data_iter = torch.utils.data.DataLoader(dataset, **eval_params)\n",
    "        for local_x, _ in train_data_iter:\n",
    "            if model.onGPU:\n",
    "                local_x = local_x.cuda(model.N_GPU)\n",
    "            x_prime = model(local_x)\n",
    "            loss, _ = criterion(local_x, x_prime)\n",
    "            aux_loss += loss.item()\n",
    "            N_batches += 1\n",
    "        batch_loss.append(aux_loss/N_batches)\n",
    "\n",
    "        printout = 'Loss: {:2.2e}'.format(batch_loss[-1])\n",
    "        if len(loss_history['train']) > 0:\n",
    "            printout += ' - Delta: {:2.2e}'.format(batch_loss[-1] - loss_history['train'][-1][-1])\n",
    "        if len(loss_history['train']) > 1:\n",
    "            d2L_de2 = batch_loss[-1] - 2*loss_history['train'][-1][-1] + loss_history['train'][-2][-1]\n",
    "            printout +=' - Trend: {:2.2e}'.format(d2L_de2)\n",
    "        print(printout)\n",
    "\n",
    "        loss_history['train'].append(batch_loss)\n",
    "\n",
    "        #### ---- Validation ---- ####\n",
    "        dataset.charge(dataset.SMMix_val)\n",
    "        val_data_iter = torch.utils.data.DataLoader(dataset, **eval_params)\n",
    "        aux_loss = 0\n",
    "        aux_feat = np.zeros((4))\n",
    "        N_batches = 0\n",
    "        for local_x, _ in val_data_iter:\n",
    "            if model.onGPU:\n",
    "                local_x = local_x.cuda(model.N_GPU)\n",
    "            x_prime = model(local_x)\n",
    "            loss, NLL_feat = criterion(local_x, x_prime)\n",
    "            if np.isnan(loss.item()) or np.isinf(loss.item()):\n",
    "                print('Invalid validation loss!!!')\n",
    "                raise NameError('LossNAN')\n",
    "            aux_loss += loss.item()\n",
    "            aux_feat += NLL_feat\n",
    "            N_batches += 1\n",
    "        loss_history['val'].append(aux_loss/N_batches)\n",
    "        loss_history['val_feat'].append(aux_feat/N_batches)\n",
    "        printout = 'Val Loss: {:2.2e}'.format(loss_history['val'][-1])\n",
    "        printout += ' Pt:{:.2f} - Eta:{:.2f} - Phi:{:.2f} - Cat:{:.2f}'.format(*loss_history['val_feat'][-1])\n",
    "        print(printout)\n",
    "        if epoch > 0:\n",
    "            if loss_history['val'][-1] < np.min(loss_history['val'][:-1]):\n",
    "                print('[INFO]: Saving best model')\n",
    "                torch.save(model.state_dict(), 'data/model_state_dict_dAE_v'+AEversion+'_best.pkl')\n",
    "\n",
    "        print('')\n",
    "        if not earlyStopping.check(loss_history['val'][-1]):\n",
    "            break\n",
    "\n",
    "        scheduler.step(batch_loss[-1])\n",
    "        \n",
    "        #### ---- Periodic save model ---- ####\n",
    "        if epoch%freq_model_save == 0:\n",
    "            torch.save(model.state_dict(), 'data/model_state_dict_dAE_v'+AEversion+'_epoch{}.pkl'.format(epoch))\n",
    "\n",
    "        #### ---- Anomaly Detection monitor ---- ####\n",
    "        if epoch%freq_AN_performance_check == 0:\n",
    "            print('------------ Anomaly Detection monitor ------------')\n",
    "            BSM_eff['ep'].append(epoch)\n",
    "            dataset.loss['SMMix'] = np.zeros((0))\n",
    "\n",
    "            pb = ProgressBar(len(val_data_iter), percentPrecision=5, headLabel='SM Mix: ')\n",
    "            for i, (local_x, _) in enumerate(val_data_iter):\n",
    "                    pb.show(i)\n",
    "                    if model.onGPU:\n",
    "                        local_x = local_x.cuda(model.N_GPU)\n",
    "\n",
    "                    x_prime = model(local_x)\n",
    "                    loss = criterion(local_x, x_prime, 'none').cpu().detach().numpy()\n",
    "                    dataset.loss['SMMix'] = np.concatenate((dataset.loss['SMMix'], loss))\n",
    "\n",
    "            p_SM = np.logspace(base=10, start=-5, stop=-3, num=3)\n",
    "            if not 'p_SM' in BSM_eff.keys():\n",
    "                BSM_eff['p_SM'] = p_SM\n",
    "            q_SM = np.quantile(dataset.loss['SMMix'], 1-p_SM)\n",
    "\n",
    "            table = PrettyTable(['SM Mix'] + list(map(lambda x: '{:1.2e}'.format(x), p_SM)))\n",
    "\n",
    "            for n in dataset.BSM_names:\n",
    "                dataset.loss[n] = np.zeros((0))\n",
    "\n",
    "                dataset.charge(dataset.valSamples[n])\n",
    "                data_iter = torch.utils.data.DataLoader(dataset, **eval_params)\n",
    "                pb = ProgressBar(len(data_iter), percentPrecision=5, headLabel=n+': ')\n",
    "                for i, (local_x, _) in enumerate(data_iter):\n",
    "                    pb.show(i)\n",
    "                    if model.onGPU:\n",
    "                        local_x = local_x.cuda(model.N_GPU)\n",
    "\n",
    "                    x_prime = model(local_x)\n",
    "                    loss = criterion(local_x, x_prime, 'none').cpu().detach().numpy()\n",
    "                    dataset.loss[n] = np.concatenate((dataset.loss[n], loss))\n",
    "\n",
    "                out = dataset.loss[n] > np.atleast_2d(q_SM).T\n",
    "                p_BSM = np.float64(np.sum(out, axis=1, dtype=np.float128)/dataset.loss[n].shape[0])\n",
    "                BSM_eff[n].append(p_BSM)\n",
    "\n",
    "                table.add_row([n] + list(map(lambda x: '{:1.2e}'.format(x), p_BSM)))\n",
    "            print(table)                \n",
    "            print('---------------------------------------------------\\n\\n')\n",
    "\n",
    "    model.eval()\n",
    "    torch.save(model.state_dict(), 'data/model_state_dict_dAE_v'+AEversion+'.pkl');\n",
    "except NameError:\n",
    "    if epoch > 0:\n",
    "        print ('\\n\\nModel ended up nan. Recovering best model\\n')\n",
    "        model.load_state_dict(torch.load('data/model_state_dict_dAE_v'+AEversion+'_best.pkl'))\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:35.342Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_history['train'] = np.array(loss_history['train'])\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "f = plt.figure(figsize=(12,8))\n",
    "\n",
    "train_loss_flat = loss_history['train'].flatten()\n",
    "x = np.arange(1, train_loss_flat.shape[0]+1) * float(loss_history['train'].shape[0])/train_loss_flat.shape[0]\n",
    "plt.plot(x, train_loss_flat, '-', alpha=0.2, color='darkorange')\n",
    "\n",
    "x = np.arange(1, loss_history['train'].shape[0]+1)\n",
    "plt.plot(x, loss_history['train'][:,-1], 'o--', label='Train', color='darkorange')\n",
    "plt.plot(x, loss_history['val'], '*', label='Validatation', color='darkmagenta')\n",
    "\n",
    "lval_feat = np.array(loss_history['val_feat'])\n",
    "plt.plot(x, lval_feat[:,0], '--.', label='NLL $P_T$', color='r')\n",
    "plt.plot(x, lval_feat[:,1], '--.', label='NLL $\\eta$', color='b')\n",
    "plt.plot(x, lval_feat[:,2], '--.', label='NLL $\\phi$', color='g')\n",
    "plt.plot(x, lval_feat[:,3], '--.', label='NLL charge-ID cat', color='k')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.grid()\n",
    "plt.legend(loc='best')\n",
    "plt.yscale('log')\n",
    "plt.ylim(1e-3, 5)\n",
    "\n",
    "f.savefig('plots/TrainingHistory_dAE_v'+AEversion+'.png')\n",
    "\n",
    "f = open('data/TrainingHistory_dAE_v'+AEversion+'.pkl', 'wb')\n",
    "pickle.dump(loss_history, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:35.586Z"
    },
    "code_folding": [
     3
    ]
   },
   "outputs": [],
   "source": [
    "f, ax_arr = plt.subplots(2,2, figsize=(12,12))\n",
    "styles = ['-', '--', ':']\n",
    "x = BSM_eff['ep']\n",
    "for i, n in enumerate(dataset.BSM_names):  \n",
    "    ax = ax_arr[int(i/2),i%2]\n",
    "    \n",
    "    BSM_eff[n] = np.array(BSM_eff[n])\n",
    "    \n",
    "    for j in range(BSM_eff['p_SM'].shape[0]):\n",
    "#         ax.plot(x, len(x)*[BSM_eff['p_SM'][j]], color='gray', lw=2, linestyle=styles[j])\n",
    "        ax.plot(x, BSM_eff[n][:,j], \n",
    "                color=dataset.process_colors[n], lw=3, linestyle=styles[j], \n",
    "                label=dataset.process_labels[n] + ' @ $\\epsilon_{{SM}} = {:1.0e}$'.format(BSM_eff['p_SM'][j]))\n",
    "        \n",
    "    ax.set_xlim([0, x[-1]+1])\n",
    "#     ax.set_ylim([1e-6, 5])\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Efficiency')\n",
    "    ax.set_title('')\n",
    "    ax.set_yscale('log')\n",
    "    ax.grid()\n",
    "    \n",
    "    ax.legend(loc='best')\n",
    "    \n",
    "f.tight_layout()\n",
    "\n",
    "f = open('data/AnomalyDetectionHistory_dAE_v'+AEversion+'.pkl', 'wb')\n",
    "pickle.dump(BSM_eff, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:35.815Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('data/model_state_dict_dAE_v'+AEversion+'_best.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convergence check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:36.619Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.charge(dataset.SMMix_val)\n",
    "x = dataset.inputs\n",
    "model.eval()\n",
    "if model.onGPU:\n",
    "    x_prime = model(torch.from_numpy(x[:10000]).cuda(model.N_GPU)).cpu().detach().numpy()\n",
    "    z = model.encode(torch.from_numpy(x[:10000]).cuda(model.N_GPU)).cpu().detach().numpy()\n",
    "else:\n",
    "    x_prime = model(torch.from_numpy(x[:10000])).cpu().detach().numpy()\n",
    "    z = model.encode(torch.from_numpy(x[:10000])).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:37.434Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(z.shape[1]):\n",
    "    x_aux = z[:,i]\n",
    "    f = plt.figure(i)\n",
    "    r = (np.min(x_aux), np.max(x_aux))\n",
    "    plt.hist(x_aux, bins=20, range=r, alpha=0.4, density=True)\n",
    "    plt.xlabel('$z_{{{}}}$'.format(i))\n",
    "    dnd.append(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:38.067Z"
    },
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    x_aux = x[:,:,i].flatten()\n",
    "    xp_aux = x_prime[:,:,i].flatten()\n",
    "        \n",
    "    f = plt.figure(i)\n",
    "    r = (min(np.min(x_aux), np.min(xp_aux)), max(np.max(x_aux), np.max(xp_aux)))\n",
    "    if i == 0:\n",
    "        r = (0,10)\n",
    "    plt.hist(x_aux, bins=31, range=r, alpha=0.4, density=True)\n",
    "    plt.hist(xp_aux, bins=31, range=r, alpha=0.4, density=True)\n",
    "    plt.xlabel('Particles ' + dataset.feature_names[i])\n",
    "#     plt.yscale('log')\n",
    "    dnd.append(f)\n",
    "    \n",
    "f = plt.figure(3)\n",
    "tc = np.argmax(x[:,:,3:], axis=-1).flatten()\n",
    "pc = np.argmax(x_prime[:,:,6:], axis=-1).flatten()\n",
    "\n",
    "plt.hist(tc, bins=np.arange(-0.5, 8.5, 1), alpha=0.4, density=True)\n",
    "plt.hist(pc, bins=np.arange(-0.5, 8.5, 1), alpha=0.4, density=True)\n",
    "plt.xticks(ticks=list(range(8)), labels=['$\\mu^+$', '$\\mu^-$', '$e^+$', '$e^-$', '$h^+$', '$h^-$', '$\\gamma$', '$h^0$'])\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum of pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:39.474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:39.858Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.loadValidationSamples('SM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:40.031Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for n in list(dataset.valSamples.keys()) + ['SMMix']:\n",
    "    dataset.loss[n] = np.zeros((0))\n",
    "    if n == 'SMMix':\n",
    "        dataset.charge(dataset.SMMix_val)\n",
    "    else:\n",
    "        dataset.charge(dataset.valSamples[n])\n",
    "    \n",
    "    data_iter = torch.utils.data.DataLoader(dataset, **eval_params)\n",
    "    pb = ProgressBar(len(data_iter), percentPrecision=5, headLabel=n+': ')\n",
    "    for i, (local_x, _) in enumerate(data_iter):\n",
    "        pb.show(i)\n",
    "        if model.onGPU:\n",
    "            local_x = local_x.cuda(model.N_GPU)\n",
    "            \n",
    "        x_prime = model(local_x)\n",
    "        loss = criterion(local_x, x_prime, 'none').cpu().detach().numpy()\n",
    "        dataset.loss[n] = np.concatenate((dataset.loss[n], loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:40.244Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ra = np.array(list(map(lambda x: [np.min(x), np.quantile(x, 1-1e-3)], dataset.loss.values())))\n",
    "r = (np.min(ra[:,0]), np.max(ra[:,1]))\n",
    "\n",
    "for n in ['Ato4l','SMMix']:\n",
    "    plt.hist(dataset.loss[n], bins=31, range=r,\n",
    "             density=True,\n",
    "             color=dataset.process_colors[n], \n",
    "             alpha=0.3, \n",
    "             label=dataset.process_labels[n])\n",
    "plt.yscale('log')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-07-18T14:15:40.440Z"
    }
   },
   "outputs": [],
   "source": [
    "dic_ROC = createROC_curve(dataset)\n",
    "pickle.dump(dic_ROC, open('data/dAE_v{}_ROC_dic.pkl'.format(AEversion), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T14:16:29.859803Z",
     "start_time": "2019-07-18T14:07:22.969Z"
    },
    "code_folding": [
     1
    ],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f_ROC, ax_arr = plt.subplots(2,2, figsize=(12,12))\n",
    "for i, n in enumerate(dataset.BSM_names):\n",
    "    f = open('../data/HLFref1811-10276_loss/VAE_all-in-one_v71_ROC1_dict_{}.pkl'.format(n), 'br')\n",
    "    dRef = pickle.load(f, encoding='bytes')\n",
    "    f.close()\n",
    "    \n",
    "    ax = ax_arr[int(i/2),i%2]\n",
    "    ax.plot(dRef[b'eff_SM'], dRef[b'eff_BSM'], label=dataset.process_labels[n] + ' HLF',\n",
    "            linestyle='--', lw=3, color=dataset.process_colors[n])\n",
    "    ax.plot(dic_ROC[n]['eff_SM'], dic_ROC[n]['eff_BSM'], label=dataset.process_labels[n] + ' PF',\n",
    "            linestyle='-', lw=3, color=dataset.process_colors[n])\n",
    "    ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle=':')\n",
    "    ax.set_xlim([1e-6, 1.0])\n",
    "    ax.set_ylim([1e-6, 1.05])\n",
    "    ax.set_xlabel('SM efficiency')\n",
    "    ax.set_ylabel('BSM efficiency')\n",
    "    ax.set_title('')\n",
    "    ax.set_yscale('log')\n",
    "    ax.set_xscale('log')\n",
    "    ax.grid()\n",
    "    \n",
    "    ax.legend(loc='lower right')\n",
    "    \n",
    "f_ROC.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent dimension clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T11:44:34.074349Z",
     "start_time": "2019-07-18T11:41:19.099Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T11:44:34.075461Z",
     "start_time": "2019-07-18T11:41:19.100Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.encoded = {}\n",
    "\n",
    "for n in dataset.BSM_names:    \n",
    "    dataset.charge(dataset.valSamples[n][:10000])\n",
    "    x_in = torch.Tensor(dataset.inputs)\n",
    "    if model.onGPU:\n",
    "        x_in = x_in.cuda(model.N_GPU)\n",
    "    dataset.encoded[n] = model.encode(x_in).cpu().detach().numpy()\n",
    "    \n",
    "dataset.charge(dataset.SMMix_val[:10000])\n",
    "x_in = torch.Tensor(dataset.inputs)\n",
    "if model.onGPU:\n",
    "        x_in = x_in.cuda(model.N_GPU)\n",
    "dataset.encoded['SMMix'] = model.encode(x_in).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T11:44:34.076565Z",
     "start_time": "2019-07-18T11:41:19.101Z"
    }
   },
   "outputs": [],
   "source": [
    "idx_max = 1000 #np.min(list(map(lambda x: x.shape[0], dataset.encoded.values())))\n",
    "z_dset = np.zeros((0, model.Nk))\n",
    "\n",
    "for n in dataset.encoded.keys():\n",
    "    z_dset = np.concatenate((z_dset, dataset.encoded[n][:idx_max]))\n",
    "    \n",
    "z_embedded = TSNE(n_components=2).fit_transform(z_dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-18T11:44:34.077708Z",
     "start_time": "2019-07-18T11:41:19.102Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(8,8))\n",
    "\n",
    "for i, n in enumerate(dataset.encoded.keys()):\n",
    "#     if not n in ['Ato4l', 'SMMix']: continue\n",
    "    aux_z = z_embedded[i*idx_max: (i+1)*idx_max]\n",
    "    plt.plot(aux_z[:,0], aux_z[:,1], \n",
    "             'o',\n",
    "             color=dataset.process_colors[n], \n",
    "             mfc='none',\n",
    "             label=dataset.process_labels[n])\n",
    "    \n",
    "plt.xlabel('Embedded 0')\n",
    "plt.ylabel('Embedded 1')\n",
    "plt.legend(loc='best')\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
